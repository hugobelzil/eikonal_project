%----------------------------------------------------------------------------------------
%    PACKAGES AND DOCUMENT CONFIGURATION
%----------------------------------------------------------------------------------------

\documentclass[11pt]{article}

% MARGINS, GEOMETRY, FONTS
\usepackage[a4paper,margin=0.7in]{geometry}  % Adjust page size and margins
\usepackage{lmodern}                       % Latin Modern font (less pixelation in PDF)
\usepackage[T1]{fontenc}                   % Better character encoding
\usepackage[utf8]{inputenc}                % UTF-8 encoding
\usepackage{amsmath,amsthm,amssymb}        % AMS math packages
%\usepackage{mathrsfs}                      % Nice script fonts
\usepackage{mathtools}                     % Extra math goodies
\usepackage{microtype}                     % Better spacing, text aesthetics
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{placeins}


\pgfplotsset{compat=1.18}
\usepgfplotslibrary{patchplots}
\usetikzlibrary{3d}

\usepackage{mathspec}
\defaultfontfeatures{Mapping=tex-text}
\usepackage{fontspec}
\setmainfont{IBM Plex Serif}

%%% PYTHON CHUNKS
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{pythonstyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegray},
    keywordstyle=\color{blue}\bfseries,
    numberstyle=\tiny\color{gray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    language=Python
}

\lstset{style=pythonstyle}


% CUSTOM HEADER AND FOOTER
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\footnotesize \textsc{Fast-Sweeping, Hugo Belzil}}
\rhead{\footnotesize \textsc{\thepage}}
\cfoot{\footnotesize \textit{}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% OTHER USEFUL PACKAGES
\usepackage{graphicx}       % For including images
\usepackage{booktabs}       % Nicer horizontal rules in tables
\usepackage{enumerate}      % For customizable lists
\usepackage{xcolor}         % For color in text/equations
\usepackage{hyperref}       % Hyperlinks in the PDF
\hypersetup{
    colorlinks = true,
    linkcolor  = blue,
    citecolor  = magenta,
    urlcolor   = teal
}

% ENVIRONMENTS (THEOREM, DEFINITION, EXAMPLE, ETC.)
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{cor}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% CUSTOM COMMANDS
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}

%----------------------------------------------------------------------------------------
%    TITLE PAGE
%----------------------------------------------------------------------------------------

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{2cm}
    {\huge \bfseries THE FAST-SWEEPING METHOD FOR EIKONAL EQUATIONS \& AN APPLICATION
    TO OPTIMAL CONTROL \par}
    \vspace{1.5cm}
    {\Large \textsc{Hugo Belzil} \par}
    \vspace{0.4cm}
    \textit{MATH 478 - Computational Methods for Applied Mathematics} \\
    \textit{Instructor: Dr.~J.C. Nave} \\
    \textit{Semester: Winter 2025} \\
    \textit{McGill University}
    \vfill
    \vspace{0.8cm}
    \includegraphics[width=0.7\textwidth]{plots/solution_3d_surface_random5.png} % Replace with your own logo or image
    \vfill
    \vspace{0.8cm}
    {\large \today\par}
\end{titlepage}

%----------------------------------------------------------------------------------------
%    TABLE OF CONTENTS (OPTIONAL)
%----------------------------------------------------------------------------------------

\tableofcontents
\thispagestyle{empty}

\clearpage

\section{Introduction}
%this is where you will describe the problem (e.g. previous work, related work,...) you are solving and the objectives
\label{sec:intro}
The Eikonal equations have several applications across many fields of mathematics, engineering, and others. They are particularly used for solving optimization problems, as we will see in this project. These equations associated to some side-condition, are of the form \\
\begin{equation}
\label{original-eikonal}
    \begin{cases}
        |\nabla u(\textbf{x})|=f(\textbf{x}) , \quad\textbf{x} \in\R^n\\
        u(\textbf{x})=\phi(\textbf{x}),\quad \textbf{x} \in \Gamma \subset \R^n
    \end{cases}
\end{equation}
where $|\cdot|$ denotes the Euclidean norm in $\R^n$, and $u,f,\phi:\R^n\xrightarrow{}\R$. Alternatively, we can rewrite \eqref{original-eikonal} as 
\begin{equation}
    \begin{cases}
        \sum_{i=1}^{n}\big(\frac{\partial u}{\partial x_i}\big)^2=f^2(\textbf{x}) , \quad\textbf{x} \in\R^n\\
        u(\textbf{x})=\phi(\textbf{x}),\quad \textbf{x} \in \Gamma \subset \R^n
    \end{cases}
\end{equation}

\noindent In this report, we will focus on solving the Eikonal equation in 2 space dimensions. We will use the discretization and fast-sweeping method proposed by Zhao in 2008. Before this, we will present some interpretations of the meaning of $u(x,y)$, as well as a use of our solution for optimal path planning.

\section{Theory}
%Introduce the equation and give some details
\subsection{Origins and derivation}
Eikonal equations are common equations, encountered in several fields of the sciences. They first arose in geometric optics problems on the propagation of light waves, the term \textit{eikonal} being a germanization of the greek word \textit{eikon}, meaning "image" or "icon". Wikipedia \ref{} We will see in section \ref{} an example where it applies to the refraction of light in changing media.
\vspace{10pt}
These equations however arise in several other fields, including optimal control theory and robotics. The solutions of eikonal equations can be used to compute optimal paths in time, as we will see in section \ref{}.
\vspace{10pt}
In particular, the differential equation (\ref{original-eikonal}) can be derived from level-set equations, for the propagation of a front for example. If we let the 0-level set of a function $\phi(\vec{x},t)$ represent a curve or a surface moving in space (being a front), we need the function $\phi$ to satisfy the advection equation: \\
\begin{equation}
\label{level_set_equation}
    \phi_t+F(\vec{x})|\nabla \phi| =0
\end{equation} \\
where $F:\vec{x}\rightarrow\R$ represents the velocity at which the point $\vec{x}$ on the curve (or surface) moves. If we restrict $F$ to be strictly positive, we force the curve to move "outwards" and extend in space. This assumption allows us the make the ansatz that $\phi$ can be expressed as : $\phi(\vec{x},t)=\psi(\vec{x})-t$. The reason for this is the following : this rewriting allows us to think of $\psi(\vec{x})$ as the arrival time of the front (the curve) to the point $\vec{x}$ in space. Indeed, recall that the curve is described as the 0-level set of $\phi(\vec{x},t)$. We can now plug-in this ansatz into (\ref{level_set_equation}) and get: \\
\begin{align*}
    & (\psi(\vec{x})-t)_t+F|\nabla(\psi(\vec{x})-t)|=0 \\
    &\implies-1 +F|\nabla\psi| = 0 \\
    &\implies |\nabla\psi|=\frac{1}{F}
\end{align*} \\
\noindent which indeed gives an Eikonal equation. In the front-propagation context, we can hence interpret the solution as the following : the arrival times $\psi$ in space of a front starting at a point $\gamma$ and propagating in a medium with speed $F$ must solve the eikonal equation
\begin{equation*}
    |\nabla\psi(\textbf{x})|=\frac{1}{F(\textbf{x})}, \quad \psi(\gamma)=0
\end{equation*}
When $F\equiv1$, the front is moving through a uniform media, at the same speed everywhere. Hence, we can view $\psi$ as the distance to $\gamma$ (see section \ref{section_on_distance}). In the analysis above, we let $\gamma$ be a single point in space, but the front could also originate from a curve, or several points in space, as we will see below. In this case, we have now a set of boundary conditions $\Gamma$.

\subsection{Distance function in 2D}
\label{section_on_distance}
An important application of Eikonal functions is the computation of Euclidean distances in $\R^n$. In particular, let us consider the following problem : suppose that we are given a  finite set of points $\Gamma = \{\gamma^{(1)},\dots,\gamma^{(m)}\}$, and for each $\textbf{x}=(x,y)$ in our computational domain, we would like to compute the shortest distance to $\Gamma$. Hence, we would like to have a function $d(x,y)$ such that
\begin{equation}
\label{min-problem}
    d(\textbf{x}) = \min_{\gamma \in \Gamma}\|\textbf{x}-\gamma\|_2
\end{equation}
Consider this problem in $\R^2$, if we let $(x,y)$ such that its closest point in $\Gamma$ is some point $\gamma^{*}=(\gamma_1,\gamma_2)$, which is the unique minimizer of \eqref{min-problem}, then:
\begin{gather*}
    d(x,y) = \sqrt{(x-\gamma_1)^2+(y-\gamma_2)^2} \\[10pt] 
    \implies\frac{\partial d}{\partial x}=\frac{x-\gamma_1}{\sqrt{(x-\gamma_1)^2+(y-\gamma_2)^2}}, \quad 
    \frac{\partial d}{\partial y}=\frac{y-\gamma_2}{\sqrt{(x-\gamma_1)^2+(y-\gamma_2)^2}} \\[10pt] 
    \implies \|\nabla d(x,y)\|^{2}_{2} = \Bigg(\frac{\partial d}{\partial x}\Bigg)^2 + \Bigg(\frac{\partial d}{\partial y}\Bigg)^2=1
\end{gather*}
Indeed, $d(x,y)$ solves the Eikonal equation where $f(x,y) \equiv 1$, and naturally we have $d(x,y)=\phi(x,y)=0$ where $(x,y)\in\Gamma$ (the distance to the boundary is 0 when the point lies on the boundary).

\vspace{5pt}

\noindent Note that we made the assumption that $\gamma^{*}$ was the only minimizer of (\ref{min-problem}). However, if $\text{card}|\Gamma|\geq2$, then there exist points in $\R^2$ for which (\ref{min-problem}) does not admit a single minimizer, but rather infinitely many. In this case, our solution $d(x,y)$ becomes non-differentiable at these points, which will be discussed in our analysis.
\section{Numerical methods}
\subsection{Discretization and scheme}
%this is where you present your numerical method/scheme. You may additionally put accuracy, stability in here. Also talk about the implementation details here.
H. Zhao proposed the fast-sweeping method in ?? to solve Eikonal equations numerically. His proposed the following discretization, which uses Gauss-Seidel iterations. In 2 dimensions, given a space step $h$, the proposed scheme is:

\begin{equation*}
    ((u_{i,j}-u_{xmin})^{+})^2+((u_{i,j}-u_{ymin})^{+})^2 = f_{i,j}^{2}h^2
\end{equation*}

\noindent where
\begin{itemize}
    \item $(x)^{+} = \max(x,0)$
    \item $u_{i,j}\approx u(ih,jh)$, $u_{xmin} = \min\{u_{i-1,j},u_{i+1,j}\}$ and $u_{ymin} = \min\{u_{i,j-1},u_{i,j+1}\}$
\end{itemize}

\noindent Figure \ref{fig:graph_discretization} shows a visualization of the scheme. The updates of the points $u_{i,j}$ must be done by "sweeping" the domain in all 4 possible directions (or $2^d$ directions in $\mathbb{R}^d$), after having initialized a grid. Without loss of generality, the sweeps in 2 dimensions can be done as follows, assuming a square domain:
\begin{itemize}
    \item \textbf{Sweep 1 : } Start from the bottom-left corner of the domain, updating the points from left to right. Hence, the last point updated is the top-right corner one.
    \item \textbf{Sweep 2 : } Start from the bottom-right corner of the domain, updating the points from right to left. This gets us to the last point updated being the top-left corner one.
    \item  \textbf{Sweep 3 : } Start from the top-left corner of the domain, updating from left to right. Similarly, the last point to be updated is the bottom-right corner one
    \item \textbf{Sweep 4 : } Last possible direction. Start from top-right corner of the domain, updating the points from right to left. The last point to be updated is the bottom left corner.
\end{itemize}

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}
        % Draw the grid points
        \foreach \x in {0,1,2} {
            \foreach \y in {0,1,2} {
                \filldraw (\x,\y) circle (3pt);
            }
        }

        % Highlight the center point (i,j)
        \filldraw[red] (1,1) circle (2pt) node[above right] {$(i,j)$};

        % Draw the stencil neighbors
        \filldraw[blue] (0,1) circle (2pt) node[left] {$(i-1,j)$};
        \filldraw[blue] (2,1) circle (2pt) node[right] {$(i+1,j)$};
        \filldraw[blue] (1,0) circle (2pt) node[below] {$(i,j-1)$};
        \filldraw[blue] (1,2) circle (2pt) node[above] {$(i,j+1)$};

        % Draw lines connecting the stencil points
        \draw[thick] (1,1) -- (0,1);
        \draw[thick] (1,1) -- (2,1);
        \draw[thick] (1,1) -- (1,0);
        \draw[thick] (1,1) -- (1,2);
    \end{tikzpicture}
    \caption{Discretization for the Fast-Sweeping method in 2D}
    \label{fig:graph_discretization}
\end{figure}

Hence, the iteration can be written as follows:
\begin{itemize}
    \item \textbf{(1)} Initialize the computational domain by setting all points to a large value $M$ (this value should be larger than the largest value of the solution $u$ in the domain).
    \item \textbf{(2)} Place the boundary conditions $\Gamma=\{\gamma_1,\dots,\gamma_m\}$ on the domain. These points are fixed and should never be updated!
    \item \textbf{(3)} Apply a batch of sweeps to the domain, i.e. sweeps 1 to 4. If needed, sweep again the domain until convergence is met. To monitor convergence, compute at the $k$-th sweep $E = \max\limits_{i,j} \left| u_{i,j}^{(k)} - u_{i,j}^{(k-1)} \right|$ where $u_ {i,j}^{(k)}$ denotes the solution on the stencil $(i,j)$ after the $k$-th sweep.
\end{itemize}
\noindent During step (\textbf{3}) in the above, one needs to solve the following equation for every point $u_{i,j}$:
\begin{equation}
\label{system_eq}
    [(u_{i,j}-a)^{+}]^2+[(u_{i,j}-b)^{+}]^2=f_{i,j}^2h^2
\end{equation}
\noindent where $a=\min\{u_{i-1,j},u_{i+1,j}\}$ and $b=\min\{u_{i,j-1},u_{i,j+1}\}$. The solution to (\ref{system_eq}) is given by:
\begin{equation*}
    \bar{u}=\begin{cases}
        \min\{a,b\}+f_{i,j}h & \text {if }|a-b|\geq f_{i,j} \\
        \frac{a+b+\sqrt{2f_{i,j}^2h^2-(a-b)^2}}{2} & \text {if }|a-b|< f_{i,j}
    \end{cases}
\end{equation*}

\subsection{Properties of the Fast-Sweeping method}
We report in this section several properties of the fast-sweeping method, some of them being shown in the results section.
\begin{prop}[\textbf{Monotonicity of the scheme}]
The fast-sweeping scheme in decreasing in the sweeps : $\forall i,j:u^{(k)}_{ij}-u^{(k-1)}_{ij}\leq0$
\end{prop}
\begin{prop}[\textbf{Number of sweeps and accuracy for distance functions}]
\label{prop_distance_functions}
    For the distance function in $\R^n$ ($F(x,y)\equiv1$), the fast-sweeping method converges in $2^n$ sweeps. However, this needs to be nuanced and argued differently. \\ \\
    If $|\Gamma|=1$, the scheme converges exactly after $2^n$ sweeps. Hence, in 2 dimensions, a $5^{th}$ sweep will not update the numerical solution $u^h$. In this case, $\|u-u^h\|_{\infty}=\mathcal{O}(|h\log h|)$ \\ \\
    If $|\Gamma|>1$, some points in the computational domain will be at the same distance to at least 2 boundary points in $\Gamma$. This creates an interaction between these boundary points and results in the following. After $2^n$ sweeps, the scheme is still $\mathcal{O}(|h\log h|)$, but further sweeps will still increase the accuracy of the numerical solution (i.e. sweeps still update the numerical solution). In this case, after $2^n+1$ sweeps or more, $\|u-u^h\|_\infty=\mathcal{O}(h)$
\end{prop}

\begin{prop}[\textbf{Number of sweeps and accuracy for general equations}]
    In the case where the velocity field $F(x,y)$ is not constant, the number of sweeps needed required to meet convergence depends on the characteristic curves, (and thus, on $F$). The accuracy for this case is $\mathcal{O}(\sqrt{h})$
\end{prop}
\noindent The proofs of these propositions are given in \ref{}.
\subsection{Code implementation}
We implement the fast-sweeping method in Python using the \texttt{numpy} library \ref{}. All the scripts are available in the GitHub repository available in the introduction \ref{}. \\
We replicate domains with the help of a class named \texttt{computational\_domain}
, equipped with the method \texttt{ComputationalDomain(N,a,b,c,d)} which instantiates an object with several attributes, including the attribute \texttt{grid} which is an $N\times N$ \texttt{Numpy} 2D array, representing the square $[a,b]\times[c,d]\subset\R^2$. The constructor of the class sets the initial value $M$ described above in section \ref{} to 100, but can be chosen by the user.\\
This class is also equipped with the method \texttt{Gamma(coordinates)} which sets the boundary conditions in the domain. \texttt{coordinates} must be a list of 2D coordinates given as a indices, for example \texttt{coordinates = [(0,0), (1,0), (4,4)]}. Note that this method assumes that the coordinates are given in Python indexing. For example, the code below would help create the following domain: \\
\begin{lstlisting}[language=Python, caption=Instance of computational domain, label=lst:fsweep]
from computational_domain import ComputationalDomain
domain = ComputationalDomain(N = 6, a = -1, b = 1, c = -1, d = 1)
domain.Gamma([(0,0), (2,1), (4,3), (1,4)])
print(domain.grid)
\end{lstlisting} \\

$$\[
\begin{bmatrix}
0 & 100 & 100 & 100 & 100 & 100 \\
100 & 100 & 100 & 100 & 0 & 100 \\
100 & 0 & 100 & 100 & 100 & 100 \\
100 & 100 & 100 & 100 & 100 & 100 \\
100 & 100 & 100 & 0 & 100 & 100 \\
100 & 100 & 100 & 100 & 100 & 100
\end{bmatrix}
\]$$ \\


\noindent The code in the repository comes with 2 classes, \texttt{eikonal\_distance\_2D} and \texttt{eikonal\_general\_F}, which help treating distinctly the cases where $F(x,y)\equiv1$ and $F(x,y)\not\equiv1$. Both classes come with a method named \texttt{EikonalSolver()}, both taking as input an object of the \texttt{computational\_domain} described above. Additionally, the \texttt{EikonalSolver} method from the general function $F$ takes as input the function $F$. An example for both cases is available below. \\

\begin{lstlisting}[language=Python, caption = Instance of an Eikonal Solver for the 2D distance function]
from computational_domain import ComputationalDomain
from solvers.eikonal_distance_2D import EikonalSolver
dom = ComputationalDomain(N = 501, a = -1, b = 1, c = -1, d = -1)
domain.Gamma([(250, 250)])

solver = EikonalSolver(domain = dom)
solver.BatchSweeps(k = 1)
print(solver.grids_after_sweeps[-1])
\end{lstlisting} \\

\noindent In this code above, we solve the Eikonal equation for the distance to the origin over the square $[-1,1]^2$ with $N=501$ grid points. The \texttt{solver} object stores the grid after each sweep, and line 8 allows to access the last grid (after the fourth sweep), which is stored as a Numpy array. The snippet below extends the method to the general case. \\

\begin{lstlisting}[language=Python, caption = Instance of an Eikonal Solver for a general velocity F]
from computational_domain import ComputationalDomain
from solvers.eikonal_general_F_2D import EikonalSolver
dom = ComputationalDomain(N = 501, a = -1, b = 1, c = -1, d = -1)
domain.Gamma([(250, 250)])
eps = 1e-6

def F(x,y):
    return 1 + x**2 + y**2

solver = EikonalSolver(domain = dom, F = F)
solver.SweepUntilConvergence(epsilon = eps, verbose = True)
print(solver.grids_after_sweeps[-1])
\end{lstlisting}

\noindent In this code above, our aim is to solve the Eikonal equation in the same domain, except that $F(x,y)=1+x^2+y^2$. Observe that we now use the method \texttt{SweepUntilConvergence}, which allows us to monitor the convergence and avoid unnecessary sweeps. After each sweep, the method computes the maximum change between the new grid and the one that had resulted from the previous sweep. If this change is below some threshold \texttt{epsilon}, the method stops. 

\section{Results}
\subsection{Distance functions in 2D}
As argued above in part \ref{}, the Eikonal equation can be used to compute the shortest distance to a boundary $\Gamma \subset \R^n$. Therefore, we test our implementation for the BVP:
\begin{equation}
\label{cone_bvp}
    \begin{cases}
        \|\nabla u(\textbf{x})\|_2=1 , \quad\textbf{x} \in[-1,1]^2\\
        u(0,0)=0
    \end{cases}
\end{equation}
The solution to this BVP is the 2D cone, given by $u(x,y)=\sqrt{x^2+y^2}$. Therefore, we can easily compare our numerical solution to the analytic one, and study its convergence as well.
For solving numerically (\ref{cone_bvp}), we discretize the square $[-1,1]^2$ uniformly with $N=257 \implies h \approx 0.0078$. The numerical solution converges after exactly 4 sweeps, as outlined by proposition (\ref{prop_distance_functions}). \\

\begin{figure}[h!]
    \centering
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/contour_plot_2D_distance.png}
        \caption{Contour plot of the numerical solution to (\ref{cone_bvp}).}
        \label{fig:contour-distance}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/solution_3d_surface.png}
        \caption{3D surface of the numerical solution.}
        \label{fig:3d-surface}
    \end{minipage}
\end{figure}
\vspace{20pt}

\noindent Figure (\ref{fig:contour-distance}) shows the contour plots of the numerical solution. Note that since the analytical solution is $u(x,y)=\sqrt{x^2+y^2}$, we would expect in theory to have perfectly round circles. However, this remains an numerical approximation, explaining why we are seeing "oval" forms rather than perfect circles. If one were to decrease the step size $h$ (i.e. increase $N$), these ovals would eventually ressemble more and more to round circles.
Figure (\ref{fig:3d-surface}) confirms as well that the numerical solution is somewhat close the cone we would expect \\

\subsubsection{Convergence}
Finally, we can analyze the convergence of the fast sweeping method for the BVP (\ref{cone_bvp}). The plot below was obtained was solving numerically the BVP, using $N\in\{201, 221,241,\dots,701\}$, converting to step sizes $h=\frac{N-1}{b-a}$. For every of these values, the numerical solutions is compared to the analytic solution. Specifically, the error is computed with the $L_\infty$ norm over the square $[-1,1]^2$. \\
On figure (\ref{fig:error_distance}) below, we see that the accuracy of the fast sweeping method is indeed of order $O(|h\log h|)$.


\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{plots/convergence2d_step_size.png}
  \caption{Accuracy of the fast-sweeping method for the distance function to the origin}
  \label{fig:error_distance}
\end{figure}

\subsection{Distance functions with several boundary points in 2D}
The example in the previous subsection was only considering one boundary value at the origin of the domain, i.e. the set $\Gamma$ was simply $\Gamma=\{(0,0)\}$. We can introduce several other boundary points, and the solution $u$ picked up by the fast sweeping-method will give at any point $(x,y)$ the distance to the closest point $\gamma\in\Gamma$, as we showed in section \ref{section_on_distance}. Indeed consider the case below, where we chose 5 points at random on $[-1,1]^2$, and set these points to be 0 in the domain. Our Eikonal solver then converges to the numerical solution $u(x,y)$ whose contours and 3D surface are given by figures (\ref{fig:contour5}) and (\ref{fig:surface5}) respectively. \\
It is easy to see on both the contour plots and on the 3D surface that the solution is non-differentiable on some lines inside the domain. In particular, the points on these lines are the ones lying at the same distance to at least 2 boundary points in $\Gamma$. In other words, the problem \ref{min-problem} does not have a unique minimizer for these sets of points.

\vspace{5pt}

\begin{figure}[h]
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{plots/contour_plot_random5.png}
    \caption{Contours of numerical solution ($|\Gamma|=5$)}
    \label{fig:contour5}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{plots/solution_3d_surface_random5.png}
    \caption{3D surface of the solution ($|\Gamma$|=5)}
    \label{fig:surface5}
  \end{minipage}
\end{figure}

\FloatBarrier

\noindent Finally, we look at another case where we introduce several more boundary points in $\Gamma$. In the example below, we sampled uniformly at random 30 points in $[-1,1]^2$ and set these points to have value 0. Figure (\ref{fig:heatmap30random}) represents a heatmap of the solution. The regions where the solution is non-differentiable are easily seen.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{plots/heatmap_random30.png}
  \caption{Distance function in 2D for $|\Gamma|=30$}
  \label{fig:heatmap30random}
\end{figure}

\newpage

\subsection{General Eikonal equations}
In this subsection, we now are interested at problems of the form of (\ref{original-eikonal}) where $f(x,y)\not\equiv 1$ on the domain. Conveniently, we will also rewrite $f(x,y)=\frac{1}{F(x,y)}$, where $F(x,y)$ can now be thought of as a velocity over the domain, as argued in the introduction. As a result, the solution $u(x,y)$ does not give the distance to the boundary anymore, but rather the "cost" of the travel from $(x,y)$ to $\Gamma$.
We test our solver for the problem.

\begin{equation}
\label{arctan_equation}
    \begin{cases}
        \|\nabla u(x,y)\|_2=\frac{1}{1+0.5(x^2+y^2)} , \quad(x,y) \in [-2,2]^2 \\
        u(0,0)= 0
    \end{cases}
\end{equation} \\

One can easily check that $u(x,y)=\sqrt{2}\arctan\Big[\sqrt{\frac{x^2+y^2}{2}}\Big]$ solves (\ref{arctan_equation}). We use this reference to test our solver with the following parameters : $N=801$ on the discretized domain $[-2,2]^2$ which gives the step size $h=0.01$, with convergence criterion $\epsilon=10^{-6}$. The contours and surface of the numerical solution are displayed below on figures (\ref{fig:contour_arctan}) and (\ref{fig:surface_arctan}). \\

\begin{figure}[h]
  \centering
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{plots/contour_plot_arctan.png}
    \caption{Contours of numerical solution where $F(x,y)=1+0.5(x^2+y^2)$}
    \label{fig:contour_arctan}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{plots/solution_3d_surface_arctan.png}
    \caption{3D surface of the numerical solution}
    \label{fig:surface_arctan}
  \end{minipage}
\end{figure}

\subsubsection{Convergence}
From Zhao, we know that for the general case $1/F(x,y)\not\equiv1$, the fast-sweeping method also converges to the true solution in $\mathcal{O}(\sqrt{h})$. For the reference problem defined in the section above, with $N\in\{21,41,\dots,401\}$, we get the following convergence to the true solution. Note that the domain is smaller than for the 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{plots/convergence2d_atan_step_size.png}
  \caption{Convergence plot}
  \label{fig:convarctan}
\end{figure}

\vspace{10pt}



\newpage

\section{An application : Path planning}
In this section, we make use of the fast-sweeping method discussed to bridge our solutions with an application : path planning. Our goal is to compute an optimal path over a domain $\Omega\subset\R^2$, starting at a point $X_0\in \R^2$ to a target set $\Gamma$. \\
In particular, one can show in optimal control theory that given the Eikonal equation set-up that we described above where $F(x,y)$ is the positive function defining the "velocity" inside, say a medium, then the shortest path in time $\textbf{X}(t)\subset \R^2$ that goes from $X_0$ to $\Gamma$ must satisfy the following diffential equation:
\begin{equation}
\label{general_form_optimal_path_DE}
    \frac{d\textbf{X}(t)}{dt}=-\nabla u(\textbf{X}(t)), \quad \textbf{X}(0)=X_0
\end{equation}

\noindent where $u$ is the solution to the Eikonal equation (\ref{original-eikonal}). In 2D, equation (\ref{general_form_optimal_path_DE}) can be rewritten as : 

\begin{equation}
\label{optimal_path_DE_2D}
    \begin{bmatrix}
        \dot{x_1}(t) \\
        \dot{x_2}(t)
    \end{bmatrix} = \begin{bmatrix}
        -\partial_xu(x_1(t),x_2(t)) \\
        -\partial_yu(x_1(t),x_2(t))
    \end{bmatrix}
\end{equation}

\noindent Several points need to be taken care of. First, observe that (\ref{optimal_path_DE_2D}) a time-continuous problem, while the solution $u$ obtained with the fast-sweeping method is discretized over a mesh with stepsize $h$. Therefore, we will need to be able to interpolate $\nabla u$ inside the cells of a mesh grid. For this, we will use bilinear interpolation.
\\
Secondly, we will discretize \ref{optimal_path_DE_2D} forward in time using time-increments $\Delta t$ 

\subsection{Bilinear interpolation}
Since our numerical solutions $u$ to Eikonal equations are available over a finite grid after using the Fast-Sweeping method, we need to be able to interpolate the values of the gradient of $u$ for points that do not lie in the grid, i.e. points that lie inside the cells of the grid. For this, we use bilinear interpolation. A visual explanation is displayed below.

Given that we know the values of the cell $u_{00},u_{01}$

\begin{tikzpicture}
  \begin{axis}[
    title={3D Plot of Bilinear Interpolation},
    xlabel={$x$},
    ylabel={$y$},
    zlabel={$z$},
    grid=major,
    view={50}{25},
  ]
    % Define corner points
    \addplot3[
      color=blue,
      mark=*]
      coordinates {
        (0, 0, 0.3) (1, 0, 0.7) (1, 1, 1) (0, 1, 0.5)
      };

    % Add connecting lines
    \addplot3[
      color=red,
      mark=none,
      line width=0.5pt]
      coordinates {
        (0,0,0.3) (1,0,0.7)
      };
    \addplot3[
      color=red,
      mark=none,
      line width=0.5pt]
      coordinates {
        (1,0,0.7) (1,1,1)
      };
    \addplot3[
      color=red,
      mark=none,
      line width=0.5pt]
      coordinates {
        (1,1,1) (0,1,0.5)
      };
    \addplot3[
      color=red,
      mark=none,
      line width=0.5pt]
      coordinates {
        (0,1,0.5) (0,0,0.3)
      };
  \end{axis}
\end{tikzpicture}





\subsection{Discretization of the ODE system}
As discussed above, we approach the differential equation \ref{optimal_path_DE_2D} using a forward-in-time Euler discretization.Let $x_i^{n}=x_i(n\Delta t), i=1,2$. The scheme is:
\begin{equation}
    \begin{cases}
        \frac{x_1^{n+1}-x_1^n}{\Delta t}=-\Tilde{u_x}(x_1^n,x_2^n) \\
        \frac{x_2^{n+1}-x_2^n}{\Delta t}=-\Tilde{u_y}(x_1^n,x_2^n)
    \end{cases} \implies
    \begin{cases}
        x_1^{n+1} = x_1^n-\Delta t\Tilde{u_x}(x_1^n,x_2^n) \\
        x_2^{n+1} = x_2^n-\Delta t\Tilde{u_y}(x_1^n,x_2^n)
    \end{cases}
\end{equation}

\noindent which we recognize as being a gradient descent, stopping when $[x_1^n,x_2^n]^T\in \Gamma$, and where $\Tilde{u_x}$ and $\Tilde{u_y}$ are the interpolated first derivatives of the numerical solution $u$.

\subsection{Example : light refraction with Snell's law}
This example covers the refraction of light when it crosses 2 media with different refraction indices. Indeed, some of the first appearances of the Eikonal equations appeared in this type of problems. Consider the following problem : we look at rays of lights in a square domain, where the lower half of the domain's refraction index is 2, and the index is 1 in the upper half plane. Consider that light is emitted at the point $X_0$ and we want to know what is the path that the rays emitted at $X_0$ will take to get to $\Gamma$. By Fermat's principle, this path is unique and is the shortest in time. However, the change of medium will make the rays of light "change" direction at the interface. \\

\begin{center}
\begin{tikzpicture}[scale=4]
  % Domain outline
  \draw[thick] (0,0) rectangle (1,1);

  % Colored background rectangles for media
  \fill[blue!10] (0,0.5) rectangle (1,1);  % upper half (n = 1)
  \fill[orange!20] (0,0) rectangle (1,0.5);  % lower half (n = 2)

  % Interface line
  \draw[dashed, thick] (0,0.5) -- (1,0.5);

  % Medium labels
  \node at (0.5,0.75) {\large$n = 1$};
  \node at (0.5,0.10) {\large$n = 2$};

  % Source point X0
  \filldraw[blue] (0.4,0.2) circle (0.015) node[below left] {$X_0$};

  % Target Gamma point
  \filldraw[red] (0.8,0.9) circle (0.015) node[above right] {$\Gamma$};

  % Refracted path
  \draw[very thick, ->] (0.4,0.2) -- (0.48,0.5);
  \draw[very thick, ->] (0.48,0.5) -- (0.8,0.9);

  % Interface label
  \node[below right] at (0.001,0.5) {Interface};

\end{tikzpicture}
\end{center}

\noindent The refractive index $n=n(x,y)$ is inversely proportional to the speed in the medium. Hence, assume that we have solved the solution to (\ref{original-eikonal}) over $[-1,1]^2$, with $F(x,y)=F_2 =2$ in the lower half of $[-1,1]^2$, and $F(x,y)=F_1 = 1$ in the upper half. We know that in each media, the path will be straight lines that will intersect at the interface domain, on the line $y=0$. Therefore, one cam compute the coordinates of the point $x$ which minimizes the time travel of light over the path from $X_0=(x_0,y_0)$ and the target $\Gamma=(x_T,y_T)$, i.e.:

\begin{equation}
\label{travel_time}
    \min_{x\in[-1,1]}T(x)=\underbrace{\frac{\sqrt{(x-x_0)^2+y_0^2}}{F_1}}_{\text{Time of travel in lower half}}+\underbrace{\frac{\sqrt{(x-x_T)^2+y_T^2}}{F_2}}_{\text{Time of travel in upper half}}
\end{equation}

\noindent Note that we strategically placed the interface on the line $y=0$, in order to simplify a bit this optimization problem. In our code, we chose $X_0=(x_0,y_0)=(0,-0.5)$ and $\Gamma =(0.5,0.5)$ which also simplifies the optimization problem. But we are still lazy and use \texttt{Scipy} in order to compute the solution to (\ref{travel_time}). \\
\noindent Our next step is to solve \ref{optimal_path_DE_2D}, and compare our path to the true path which we obtained above by computing the $x$-coordinate on the interface. We use the \texttt{solvers.ODE\_backtracer} method available in the repository and obtain the path below.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{plots/snell_path.png}
  \caption{Backtraced path from $X_0$ to $\Gamma$ using the numerical solution to the ODE system (\ref{optimal_path_DE_2D})}
  \label{fig:snell_path}
\end{figure}

\noindent This path seems correct but we would like to confirm that our implementation does converge to the true solution. Luckily, the previous work we did to compute the $x$-coordinate on the line $y=0$ can be compared with our path. For this purpose, we introduce the Hausdorff distance: \\

\vspace{5pt}

\noindent\textbf{Hausdorff distance between 2 curves :} Given 2 curves $S_1,S_2\subset \mathbb{R}^n$, the Hausdorff distance is a measure that quantifies how close in curves are to each other. It if formally defined as:
\begin{equation*}
    d_H(S_1,S_2)=\max\{\sup_{s_1\in S_1}d(s_1,S_2),\sup_{s_2\in S_2}d(S_1,s_2)\}
\end{equation*}
where $d(x,y)$ be a metric on $\R^2$. In our case, we only consider the euclidean metric. Indeed, $d_H(S_1,S_2)=0\iff S_1=S_2$, and $S_n\xrightarrow{n\to\infty}S\iff\lim_{n\to\infty}d_H(S_n,S)=0$.
Therefore, after obtaining our true path using Snell's law, we solve the ODE problem with several values of $\Delta t$, and compute $d_H(S_{\Delta_t},S)$ where $S_{\Delta_t}$ denotes the numerical path computed, and $S$ denotes the true path computed with Snell's law. We expect $d_H(S_{\Delta_t},S)\xrightarrow{\Delta_t\to0}0$, and that is what we obtain indeed:

\end{document}


